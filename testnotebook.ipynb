{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(img, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPS:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(fps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m70\u001b[39m),\n\u001b[0;32m     68\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_PLAIN, \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     69\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m,img)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import HandTrackingModule as htm\n",
    "import math\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui\n",
    "\n",
    "wCam, hCam = 640, 480\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,wCam)\n",
    "cap.set(4,hCam)\n",
    "pTime = 0\n",
    "frameR=100\n",
    "smoothening=12\n",
    "plocX,plocY=0,0\n",
    "clocX,clocY=0,0\n",
    "\n",
    "\n",
    "detector=htm.HandDetector(maxHands=1)\n",
    "wScreen,hScreen=pyautogui.size()\n",
    "pyautogui.FAILSAFE=False\n",
    "\n",
    "while True:\n",
    "    success,img=cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    img=detector.findHands(img)\n",
    "    lmList,bbox=detector.findPosition(img)\n",
    "    \n",
    "    if len(lmList)!=0:\n",
    "        [x1,y1]=lmList[8][1:]\n",
    "        [x2,y2]=lmList[12][1:]\n",
    "        fingers=detector.fingersUp()\n",
    "        cv2.rectangle(img,(frameR,frameR),(wCam-frameR,hCam-frameR),(255,0,255),2)\n",
    "        \n",
    "        # For hovering\n",
    "        if fingers[1]==1 and fingers[2]==0:\n",
    "            \n",
    "            x3=np.interp(x1,(frameR,wCam-frameR),(0,wScreen))\n",
    "            y3=np.interp(y1,(frameR,hCam-frameR),(0,hScreen))\n",
    "            \n",
    "            clocX=plocX+(x3-plocX)/smoothening\n",
    "            clocY=plocY+(y3-plocY)/smoothening\n",
    "            \n",
    "            pyautogui.moveTo(clocX,clocY)\n",
    "            plocX,plocY=clocX,clocY\n",
    "        \n",
    "        # Left click functionality\n",
    "        \n",
    "        if fingers[1]==1 and fingers[2]==1:\n",
    "            length,img,lineInfo=detector.findDistance(8,12,img)\n",
    "            # print(length)\n",
    "            if length<40:\n",
    "                pyautogui.click()\n",
    "        \n",
    "        # Design for right click\n",
    "        if fingers[1]==1 and fingers[2]==0:\n",
    "            if fingers[4]==1:\n",
    "                pyautogui.rightClick()\n",
    "                \n",
    "        \n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.putText(img, f'FPS:{int(fps)}', (48, 70),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import HandTrackingModule as htm\n",
    "import math\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "\n",
    "wCam, hCam = 640, 480\n",
    "# boundingBox=[]\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "pTime = 0\n",
    "\n",
    "\n",
    "detector = htm.HandDetector(maxHands=1)\n",
    "\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(\n",
    "    IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = interface.QueryInterface(IAudioEndpointVolume)\n",
    "volumeRange = volume.GetVolumeRange()\n",
    "minimumVolume = volumeRange[0]\n",
    "maximumVolume = volumeRange[1]\n",
    "area = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)  # Flipping is needed to create mirroring\n",
    "    # Find the hands\n",
    "    detector.findHands(img)\n",
    "    lmList, boundingBox = detector.findPosition(img, handNo=0, draw=True)\n",
    "    if len(lmList) != 0:\n",
    "        # Filter based on size\n",
    "        area = (boundingBox[2]-boundingBox[0]) * \\\n",
    "            (boundingBox[3]-boundingBox[1])//100\n",
    "        # print(area)\n",
    "        if 100 < area < 900:\n",
    "\n",
    "            # Find the distance btwn index and thumb\n",
    "            length, img, lineInfo = detector.findDistance(4, 8, img=img)\n",
    "\n",
    "            # Converting length to volume\n",
    "            vol = np.interp(length, [10, 150], [0, 100])\n",
    "\n",
    "            # Reduce resolution to make smoother.\n",
    "            smoothness = 5\n",
    "            vol = smoothness*round(vol/smoothness)\n",
    "\n",
    "            # Check fingers which are up\n",
    "            fingers=detector.fingersUp()\n",
    "          \n",
    "\n",
    "            # if pinky is down then set volume\n",
    "            if not fingers[4]:\n",
    "                volume.SetMasterVolumeLevelScalar(vol/100, None)\n",
    "\n",
    "            # drawings\n",
    "\n",
    "            # Frame rate\n",
    "\n",
    "            \n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.putText(img, f'FPS:{int(fps)}', (48, 70),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
